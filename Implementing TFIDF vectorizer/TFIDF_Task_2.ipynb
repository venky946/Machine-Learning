{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5b. Assignment_tfidf_Task_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HwW1fke2hdK"
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEtfgEEb28aY"
      },
      "source": [
        "def fit_50(corpus):\n",
        "  #creating set for storing unique_words\n",
        "  u_w = set()\n",
        "  if isinstance(corpus, list):\n",
        "    #iterating through rows in corpus\n",
        "    for row in corpus:\n",
        "      #iterating through each words in row\n",
        "      for words in row.split():\n",
        "        #checking for length of words\n",
        "        if len(words) < 2:\n",
        "          continue\n",
        "        #adding each words in set\n",
        "        u_w.add(words)\n",
        "\n",
        "    #converting set into sorted list\n",
        "    u_w = list(u_w)\n",
        "\n",
        "    #creating dict with words in list as keys and enumerated index as values\n",
        "    vocab = {j:i for i, j in enumerate(u_w)}\n",
        "\n",
        "    #creating dict with keys in vocab dict as keys and its idf as values\n",
        "    vocab_idf = {word:get_idf_50(word,corpus) for word in vocab.keys()}\n",
        "\n",
        "    #gettingtop 50 values based on idf values\n",
        "    vocab_idf_50 = dict(sorted(vocab_idf.items(),key=operator.itemgetter(1),reverse=True)[:50])\n",
        "\n",
        "    #creating dict with top 50 words as keys and its enumerated index as values\n",
        "    vocab_50 = {j:i for i, j in enumerate(vocab_idf_50.keys())}\n",
        "    \n",
        "    return vocab_50\n",
        "  else:\n",
        "    print(\"Send list of Sentences\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aEtpQyu6LSa"
      },
      "source": [
        "def transform_50(corpus, vocab_50):\n",
        "  #creating empty lists for rows, column, values\n",
        "  rows = []\n",
        "  columns = []\n",
        "  values = []\n",
        "  if isinstance(corpus, list):\n",
        "    #iterating through rows in corpus\n",
        "    for idx, row in enumerate(corpus):\n",
        "      #creating dict with words in row and its count as values\n",
        "      word_freq = dict(Counter(row.split()))\n",
        "      #iterating through keys in top 50 vocab dict\n",
        "      for word in vocab_50.keys():\n",
        "\n",
        "        tfidf = (word_freq.get(word, 0) / len(row.split())) * get_idf_50(word, corpus)\n",
        "\n",
        "        if tfidf != 0:\n",
        "          #appending row index(idx) into row list\n",
        "          rows.append(idx)\n",
        "\n",
        "          #getting column index from top 50 vocab dict\n",
        "          col_index = vocab_50.get(word, 0)\n",
        "          columns.append(col_index)\n",
        "\n",
        "          #appending tfidf to values list\n",
        "          values.append(tfidf)\n",
        "    #norm = normalize(values)\n",
        "\n",
        "    #return csr_matrix(norm)\n",
        "    return csr_matrix((values, (rows, columns)), shape=(len(corpus),len(vocab_50)))\n",
        "  else:\n",
        "    print(\"Send list of Sentences\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBC4uddO3D4T"
      },
      "source": [
        "def get_idf_50(word, corpus):\n",
        "  count=0\n",
        "  #iterating through rows in corpus\n",
        "  for r in corpus:\n",
        "    #if word in that row increament count by one\n",
        "    if word in r:\n",
        "      count += 1\n",
        "  idf_key= 1 + math.log((1+len(corpus)) / (count+1))\n",
        "  return idf_key"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zxAIHiM28eY",
        "outputId": "b5a213f2-5a16-4950-e24e-2183afbe52d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq717pVb3DwM",
        "outputId": "b2e6b945-3ac3-4271-86cb-480219af3251"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/Dataset/cleaned_strings', 'rb') as f:\n",
        "    corpus = pickle.load(f)\n",
        "    \n",
        "# printing the length of the corpus loaded\n",
        "print(\"Number of documents in corpus = \",len(corpus))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in corpus =  746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co_Tbm1n3L43",
        "outputId": "f27214aa-47ed-44a6-907d-8cc3e83bf0aa"
      },
      "source": [
        "#printing keys in top 50 vocab dict\n",
        "vocab_50 = fit_50(corpus)\n",
        "print(list(vocab_50.keys()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['garfield', 'tongue', 'sacrifice', 'superlative', 'cheerless', 'guys', 'letting', 'stick', 'anatomist', 'slightly', 'gaudi', 'flying', 'knocked', 'netflix', 'telephone', 'crew', 'hoffman', 'indictment', 'enjoyment', 'upa', 'pseudo', 'keith', 'starring', 'inside', 'falls', 'pulls', 'roller', 'spiffy', 'discomfort', 'sculpture', 'distant', 'grade', 'wants', 'excessively', 'marbles', 'wondered', 'yun', 'gere', 'switched', 'murdering', 'anthony', 'vivian', 'sour', 'thorsen', 'houses', 'random', 'worry', 'voyage', 'reflected', 'undertone']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNcGufqI9pqu",
        "outputId": "11ccfd51-2c8e-473a-8221-3c2fd1959f69"
      },
      "source": [
        "#top 50 idf values after fit method\n",
        "idf_lst = [get_idf_50(i, corpus) for i in vocab_50.keys()]\n",
        "print(idf_lst)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmjhX0DUNmxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de3b541-f90c-4f81-b774-3f7f60623d1c"
      },
      "source": [
        "#shape of output matrix\n",
        "print(numpy.shape(transform_50(corpus, vocab_50).toarray()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(746, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnE0s4Xm3L00",
        "outputId": "b059af6f-8e6a-4bc3-e2bf-1471c47253a8"
      },
      "source": [
        "tr = transform_50(corpus, vocab_50)\n",
        "print(tr[19])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 3)\t0.015769744885131828\n",
            "  (0, 25)\t0.015769744885131828\n",
            "  (0, 26)\t0.015769744885131828\n",
            "  (0, 46)\t0.015769744885131828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAzIharvBdyD",
        "outputId": "40f007bd-17b7-4c57-c477-a17db5accd7f"
      },
      "source": [
        "print(tr[19].toarray())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.01576974 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.01576974 0.01576974 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.01576974 0.\n",
            "  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdTNi2B-W_as"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}